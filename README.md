# Проведение контролируемых экспериментов в классической среде (Acrobot-v1)

Исследование в рамках Трека 1. Обучение агента в классической среде

## Структура проекта:
```
RL_Track1\
├── RL_Track1.ipynb
├── logs\
│   ├── baseline\             # gamma=0.99, архитектура [64,64] (по умолчанию)
│   │   ├── baseline.monitor.csv
│   │   └── tensorboard\
│   └── gamma_0999\          # Эксперимент 1: gamma=0.999, архитектура [64,64]
│   │   ├── gamma_0999.monitor.csv
│   │   └── tensorboard\
│   ├── net_small\            # Эксперимент 2: gamma=0.99, архитектура [32,32]
│   │   ├── net_small.monitor.csv
│   │   └── tensorboard\
│   ├── net_large\            # Эксперимент 2: gamma=0.99, архитектура [256,256]
│   │   ├── net_large.monitor.csv
│   └── └── tensorboard\
├── models\
│   ├── ppo_acrobot_baseline.zip
│   ├── ppo_acrobot_gamma_0999.zip
│   ├── ppo_acrobot_net_small.zip
│   └── ppo_acrobot_net_large.zip
├── videos\
│   ├── baseline.mp4
│   ├── gamma_0.999.mp4
│   ├── net_small.mp4 
└── └── net_large.mp4 
```

В папках сохранены артефакты исследования: логи, файлы мониторинга, видеозаписи восстановленных финальных эпизодов

## Настройка окружения

1. Клонирование репозитория
```bash
git clone https://github.com/ваш_логин/RL_track1.git
cd RL_track1
```
2. Создание виртуального окружения (рекомендуется python 3.11.9)
```bash
# Linux/Mac
python -m venv .venv
source .venv/bin/activate

# Windows
python -m venv .venv
.\.venv\Scripts\activate
```

3. Установка зависимостей
```bash
pip install -r requirements.txt
```

## Работоспособность кода

Проверяется последовательным выполнением ячеек в файле .ipynb

## Результаты исследования

В ходе проведенного исследования было выполнено обучение агента в среде Acrobot-v1 с использованием алгоритма PPO, а также проведены два контролируемых эксперимента для анализа влияния ключевых гиперпараметров на процесс обучения и качество решения.

Первый эксперимент, посвященный изучению влияния коэффициента дисконтирования gamma, показал, что увеличение значения gamma с 0.99 до 0.999 практически не повлияло на общую эффективность обучения. Хотя модель с увеличенным gamma продемонстрировала лучший результат в отдельном финальном эпизоде, базовая модель с gamma=0.99 показала более высокую стабильность и эффективность в среднем, пройдя большее количество эпизодов за то же время обучения.

Второй эксперимент, исследующий влияние архитектуры нейронной сети, выявил более значимые различия. Увеличение размера сети до [256, 256] нейронов позволило достичь лучших средних результатов обучения, что проявилось в большем количестве пройденных эпизодов и более высокой средней награде. Однако между средними показателями и результатами в отдельных эпизодах было заметно расхождение: при тестировании базовая архитектура [64, 64] показала лучшую эффективность, чем увеличенная сеть.

Полученные результаты демонстрируют важность эмпирического подбора гиперпараметров с учетом специфики конкретной среды. Для задачи Acrobot-v1 выбор архитектуры нейронной сети оказался значительно более важным фактором, чем настройка коэффициента дисконтирования. Базовая архитектура [64, 64], используемая по умолчанию в реализации Stable Baselines3, обеспечивает оптимальный баланс между производительностью обучения и стабильностью работы агента
